Documento de Projeto: paparazzi-worker
Versão: 0.5
Data: 26 de Junho de 2025

Histórico de Alterações (v0.5):

Módulo 1 (Detecção): Arquitetura totalmente revisada. O 

detector.py agora utiliza a API do YouTube em vez de RSS, permitindo uma busca mais profunda e a filtragem de Shorts pela duração do vídeo.

* 

Módulo 2 (Coleta): Adicionada a dependência explícita do FFmpeg para a junção de áudio e vídeo pelo yt-dlp. 

Módulo 3 (Roteirização): Arquitetura de IA detalhada. Adotada uma sub-pipeline (Extração de Áudio -> Transcrição com Whisper -> Análise com LLM). 

Roadmap: A Fase 1 (Infraestrutura e Detecção Híbrida) foi marcada como CONCLUÍDA. O foco atual do projeto foi movido para a Fase 2 (MVP do Módulo 3).

1. Visão Geral do Projeto

Conceito: Uma "Fábrica de Clipes Virais" automatizada. 


Objetivo: Ser a fonte mais rápida e inteligente de cortes de alta qualidade para nichos específicos, transformando conteúdo longo em dezenas de peças de conteúdo curto com o mínimo de intervenção humana. 


Produto Final: Vídeos de 15 a 90 segundos no formato vertical (9:16), com legendas dinâmicas e otimizados para engajamento. 

2. O Fluxo de Trabalho (Pipeline de Automação)
O processo é dividido em módulos sequenciais, com uma lógica de gatilho condicional. 

Módulo 1: Detecção (O Vigia e Classificador)


Entrada: Uma lista de canais do YouTube para monitorar. 


Saída: Um alerta de "Download Imediato" ou um "Registro para Observação". 

Módulo 2: Coleta (O Baixador)


Entrada: O alerta de vídeo relevante, que pode vir do Módulo 1 ou do watcher.py. 


Saída: O arquivo de vídeo completo (.mp4) salvo localmente. 

Módulo 3: Roteirização (O Garimpeiro de IA)


Entrada: O arquivo de vídeo completo (.mp4). 


Saída: Um "pacote de cortes" em formato JSON, com timestamps e justificativas geradas por IA. 

Módulo 4: Geração do Vídeo (A Linha de Montagem)


Entrada: O pacote de cortes (JSON) e o vídeo original (.mp4). 


Saída: Múltiplos arquivos de vídeo finais (.mp4), um para cada corte. 

3. Detalhamento dos Módulos (Revisado para v0.5)
Módulo 1: detector.py (O Vigia com Super Visão)

O que precisa fazer: Monitorar canais via API do YouTube para encontrar o vídeo longo mais recente. Ele busca os últimos vídeos, filtra os "Shorts" analisando a duração de cada um, e então classifica o primeiro vídeo longo encontrado.


SE o título contém um nome da influencers.txt, ENTÃO gera um alerta de "Download Imediato". 


SE NÃO, salva o ID do vídeo em uma base de dados (watch_list.db) para ser analisado pelo watcher.py. 


Fontes de Dados: API do YouTube, arquivo influencers.txt. 


Tecnologia Chave: google-api-python-client, isodate. 

Componente: watcher.py (O Analista de Performance)

O que precisa fazer: Rodar periodicamente (ex: a cada 4 horas) para analisar a "lista de observação". Para cada vídeo, verifica se tem menos de 3 dias, usa a API do YouTube para obter as visualizações e, se for maior que 200.000, gera um alerta de "Download Aprovado" para o Módulo 2. 


Fontes de Dados: Banco de dados watch_list.db (SQLite), API do YouTube. 


Tecnologia Chave: SQLite, google-api-python-client. 

Módulo 2: coletor.py (O Baixador)


O que precisa fazer: Usar o link do alerta para baixar o vídeo completo. É acionado tanto pelo 

detector.py quanto pelo watcher.py. 


Tecnologia Chave: yt-dlp e sua dependência FFmpeg. 

Módulo 3: roteirizador.py (O Garimpeiro de IA)

O que precisa fazer: Analisar um vídeo longo e, usando uma cadeia de ferramentas de IA, identificar e extrair os metadados dos segmentos com maior potencial viral.

Extração de Áudio: Usa FFmpeg para extrair o áudio do .mp4.


Transcrição: Usa um modelo Whisper local para transcrever o áudio, gerando um texto com timestamps. 

Análise com LLM: Envia a transcrição para um LLM local (ex: DeepSeek V3) via API para que a IA identifique os melhores momentos e retorne os timestamps.


Tecnologia Chave: FFmpeg, Whisper, requests (para API do LLM). 

Módulo 4: gerador.py (A Linha de Montagem)


O que precisa fazer: Cortará o vídeo original nos timestamps definidos pelo Módulo 3. 


Tecnologia Chave: FFmpeg. 

4. Próximos Passos (Roadmap de Desenvolvimento)
Fase 1: MVP - Fábrica de Clipes Híbrida (CONCLUÍDA)


Status: O fluxo completo de Detecção , Incubação e Coleta  foi construído, depurado e validado. A infraestrutura de base está operacional.



Fase 2: O Cérebro da Operação - MVP do Módulo 3 (Foco Atual)

Objetivo: Construir e validar a pipeline de roteirização, provando que conseguimos transformar um arquivo de vídeo em uma lista de clipes sugeridos pela IA.

Passos:

Configuração de Ambiente (IA): Instalar as bibliotecas necessárias para a execução local do Whisper.

Desenvolvimento do roteirizador.py para executar a extração de áudio e a transcrição.

Integração com a API do LLM local, incluindo a criação de um prompt eficaz.

Teste de Ponta a Ponta do Módulo 3.

Fase 3: Automação Completa e Visão Futura (Backlog)


Objetivo: Finalizar a automação e tornar o sistema autossuficiente. 

Passos:

Integração do Módulo 4: Construir o gerador.py.


Desenvolver Módulo 5 ("Radar de Talentos"): Implementar o sistema adaptativo que descobre novos influenciadores para monitorar. 