# --- paparazzi-worker: M√≥dulo 1 (Detec√ß√£o) ---
# Vers√£o 0.7: Monitor com "Batching" de Palavras-Chave

import tweepy
import time
from datetime import datetime, timezone
import math

# --- 1. CONFIGURA√á√ÉO ---
BEARER_TOKEN = "AAAAAAAAAAAAAAAAAAAAABKK2QEAAAAAQZeWvqeP1Ji73OoVHh84rf2zhxM%3DX9MzWoEC98p2gk1nUU37pOcUlZifqcJpIRfhJTZigvQoseSdA3"

LISTA_DE_ALVOS = ["whindersson", "felipeneto", "Virginia", "g1"]
LISTA_DE_PALAVRAS_CHAVE = [
    "treta", "pol√™mica", "cancelado", "processo",
    "namorando", "separou", "trai√ß√£o", "gravida"
]

INTERVALO_EM_MINUTOS = 15
PERCENTUAL_DE_ALERTA = 0.0005
# NOVO PAR√ÇMETRO: Define o tamanho de cada lote de palavras-chave
TAMANHO_DO_LOTE = 3


# --- 2. FUN√á√ÉO AUXILIAR PARA DIVIDIR A LISTA ---
def dividir_em_lotes(lista, tamanho_lote):
    """Divide uma lista em lotes menores de um tamanho espec√≠fico."""
    for i in range(0, len(lista), tamanho_lote):
        yield lista[i:i + tamanho_lote]


# --- 3. L√ìGICA DO MONITOR ---
def monitorar_com_batching():
    print(f"‚úÖ Monitor de Pol√™micas v0.7 (Batching) iniciado. Tamanho do lote: {TAMANHO_DO_LOTE}")
    client = tweepy.Client(BEARER_TOKEN)

    # Divide a lista de palavras-chave em lotes UMA S√ì VEZ
    lotes_de_palavras = list(dividir_em_lotes(LISTA_DE_PALAVRAS_CHAVE, TAMANHO_DO_LOTE))
    print(f"Palavras-chave divididas em {len(lotes_de_palavras)} lotes.")

    while True:
        print("-" * 70)
        agora = datetime.now(timezone.utc)
        print(f"[{agora.strftime('%Y-%m-%d %H:%M:%S')}] Iniciando novo ciclo...")

        for influenciador in LISTA_DE_ALVOS:
            contagem_acumulada = 0
            try:
                print(f"\nVerificando @{influenciador}...")
                user_response = client.get_user(username=influenciador, user_fields=["public_metrics"])
                if user_response.data is None: continue

                num_seguidores = user_response.data.public_metrics['followers_count']
                limite_dinamico = math.ceil(num_seguidores * PERCENTUAL_DE_ALERTA)
                print(f"  -> Limite din√¢mico: {limite_dinamico} men√ß√µes.")

                # Loop atrav√©s dos LOTES de palavras, n√£o da lista inteira
                for i, lote in enumerate(lotes_de_palavras):
                    or_clause = " OR ".join([f'"{palavra}"' for palavra in lote])
                    query_keywords_part = f"({or_clause})"
                    query = f'"{influenciador}" {query_keywords_part} -is:retweet'

                    print(f"  -> Buscando Lote {i + 1}/{len(lotes_de_palavras)}: {lote}")

                    response = client.get_recent_tweets_count(query=query)
                    contagem_do_lote = response.meta['total_tweet_count']
                    contagem_acumulada += contagem_do_lote

                    print(f"     -> Resultado do lote: {contagem_do_lote} tweets.")
                    # Pausa CR√çTICA para dar um respiro √† API entre as buscas complexas
                    time.sleep(5)

                print(f"  -> Volume total de buzz acumulado: {contagem_acumulada} tweets.")

                if contagem_acumulada > limite_dinamico:
                    print("\nüî•üî•üî• ALERTA DE TEND√äNCIA! N√çVEL ALTO! üî•üî•üî•")
                    print(f"Assunto: Alta atividade para '{influenciador}'.")
                    print(f"Volume: {contagem_acumulada} tweets (Limite era {limite_dinamico}).")

            except Exception as e:
                print(f"  -> ‚ùå AVISO: Ocorreu um erro ao processar @{influenciador}. Continuando...")
                print(f"     Detalhe do erro: {e}")
                if "429" in str(e):
                    print("     -> Rate Limit. Saindo do loop deste influenciador para o pr√≥ximo ciclo.")
                    break

        print(f"\nüèÅ Ciclo de verifica√ß√£o completo. Pr√≥ximo ciclo em {INTERVALO_EM_MINUTOS} minutos.")
        time.sleep(INTERVALO_EM_MINUTOS * 60)


# --- 4. EXECU√á√ÉO ---
if __name__ == "__main__":
    if BEARER_TOKEN == "SEU_BEARER_TOKEN_AQUI":
        print("üõë ATEN√á√ÉO: Voc√™ precisa configurar seu BEARER_TOKEN no c√≥digo antes de rodar.")
    else:
        monitorar_com_batching()